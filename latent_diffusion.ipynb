{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fa1c9b",
   "metadata": {},
   "source": [
    "# Latent Diffusion\n",
    "\n",
    "WIP implementation of latent diffusion from the paper [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752).\n",
    "\n",
    "Resources Used:\n",
    "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "- [Variational AutoEncoder](https://keras.io/examples/generative/vae/)\n",
    "- [Denoising Diffusion Implicit Models](https://keras.io/examples/generative/ddim/)\n",
    "\n",
    "ToDo:\n",
    "- Find colored dataset to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9252187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338ad422",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size  = 28\n",
    "autoencoder_depth = 10\n",
    "dropout = 0.1\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcb6ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], image_size, image_size, channels))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], image_size, image_size, channels))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79204bc6",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2491f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncoderBlock():\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        return encoded\n",
    "    \n",
    "    return apply\n",
    "\n",
    "def DecoderBlock():\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        return decoded\n",
    "    \n",
    "    return apply\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(4, 4, 8))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f94ed510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = self.create_encoder()\n",
    "        self.decoder = self.create_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def create_encoder(self):\n",
    "        input_image = layers.Input(shape=(image_size, image_size, channels))\n",
    "        x = EncoderBlock()(input_image)\n",
    "        z_mean = layers.Conv2D(8, (2, 2), padding='same')(x)\n",
    "        z_log_var = layers.Conv2D(8, (2, 2), padding='same')(x)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "        return keras.Model(input_image, [z_mean, z_log_var, z])\n",
    "    \n",
    "    def create_decoder(self):\n",
    "        input_latent = layers.Input(shape=(4, 4, 8))\n",
    "        decoded = DecoderBlock()(input_latent)\n",
    "        return keras.Model(input_latent, decoded)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def encode(self, data):\n",
    "        _, _, z = self.encoder(data)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, data):\n",
    "        x = self.decoder(data)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5dff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "vae.compile(optimizer='adam')\n",
    "vae.fit(x_train, epochs=200, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e86d681c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([59904, 4, 4, 8])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_images = vae.encode(x_train[0 : batch_size])\n",
    "batch_size = 512\n",
    "\n",
    "for i in range(1, int(x_train.shape[0] / batch_size)):\n",
    "    encoded = vae.encode(x_train[i*batch_size : i * batch_size + batch_size])\n",
    "    encoded_images = tf.concat([encoded_images, encoded], axis=0)\n",
    "\n",
    "encoded_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ea742850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206f6475cc8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(encoded_images[0].numpy().reshape(4, 4 * 8), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8ac1730a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([59904, 28, 28, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_images = vae.decode(encoded_images[0 : batch_size])\n",
    "batch_size = 512\n",
    "\n",
    "for i in range(1, int(x_train.shape[0] / batch_size)):\n",
    "    decoded = vae.decode(encoded_images[i*batch_size : i * batch_size + batch_size])\n",
    "    decoded_images = tf.concat([decoded_images, decoded], axis=0)\n",
    "\n",
    "decoded_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b177e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206ef70cec8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(decoded_images[1].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83990d5",
   "metadata": {},
   "source": [
    "## Denoising U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "256b8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling.\n",
    "min_signal_rate = 0.02\n",
    "max_signal_rate = 0.95\n",
    "\n",
    "# Architecture.\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "widths = [32, 64, 96, 128]\n",
    "block_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1adee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_schedule(diffusion_times):\n",
    "    start_angle = tf.acos(max_signal_rate)\n",
    "    end_angle = tf.acos(min_signal_rate)\n",
    "\n",
    "    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "\n",
    "    signal_rates = tf.cos(diffusion_angles)\n",
    "    noise_rates = tf.sin(diffusion_angles)\n",
    "\n",
    "    return noise_rates, signal_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10013591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):\n",
    "    embedding_min_frequency = 1.0\n",
    "    frequencies = tf.exp(tf.linspace(tf.math.log(embedding_min_frequency),\n",
    "                         tf.math.log(embedding_max_frequency),\n",
    "                         embedding_dims // 2))\n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat([tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b720f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(width):\n",
    "    def apply(x):\n",
    "        input_width = x.shape[3]\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(width, (1, 1))(x)\n",
    "            \n",
    "        x = layers.Conv2D(width, (3, 3), padding='same', activation=keras.activations.swish)(x)\n",
    "        x = layers.LayerNormalization()(x + residual)\n",
    "        return x\n",
    "    \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb554cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x)\n",
    "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "        return x\n",
    "        \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ada302ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation='bilinear')(x)\n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x)\n",
    "        return x\n",
    "    \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3472ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unet(widths, block_depth):\n",
    "    noisy_images = keras.Input(shape=(4, 4, 8))\n",
    "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
    "\n",
    "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
    "    e = layers.UpSampling2D(size=4, interpolation=\"nearest\")(e)\n",
    "\n",
    "    x = layers.Conv2D(widths[0], kernel_size=1)(noisy_images)\n",
    "    x = layers.Concatenate()([x, e])\n",
    "\n",
    "    for width in widths[:-1]:\n",
    "        x = DownBlock(width, block_depth)(x)\n",
    "\n",
    "    for _ in range(block_depth):\n",
    "        x = ResidualBlock(widths[-1])(x)\n",
    "\n",
    "    for width in reversed(widths[:-1]):\n",
    "        x = UpBlock(width, block_depth)(x)\n",
    "\n",
    "    x = layers.Conv2D(8, kernel_size=1, kernel_initializer=\"zeros\")(x)\n",
    "    \n",
    "    unet = keras.Model([noisy_images, noise_variances], x, name=\"residual_unet\")\n",
    "    unet.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f28b04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, model, epochs, batch_size):\n",
    "    steps_per_epoch = int(train_data.shape[0] / batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(steps_per_epoch):\n",
    "            images = train_data[step * batch_size : step * batch_size + batch_size]\n",
    "            noises = tf.random.normal(shape=(batch_size, 4, 4, 8))\n",
    "            \n",
    "            diffusion_times = tf.random.uniform(shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0)\n",
    "            noise_rates, signal_rates = diffusion_schedule(diffusion_times)\n",
    "\n",
    "            noisy_images = signal_rates * images + noise_rates * noises\n",
    "            model.train_on_batch([noisy_images, noise_rates**2], noises)\n",
    "        \n",
    "        print('Epoch ' + str(epoch) + ' completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17defb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_diffusion(model, num_images, diffusion_steps):\n",
    "    initial_noise = tf.random.normal(shape=(num_images, 4, 4, 8))\n",
    "    step_size = 1.0 / diffusion_steps\n",
    "    \n",
    "    next_noisy_images = initial_noise\n",
    "    for step in range(diffusion_steps):\n",
    "        noisy_images = next_noisy_images\n",
    "        \n",
    "        diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
    "        noise_rates, signal_rates = diffusion_schedule(diffusion_times)\n",
    "        \n",
    "        pred_noises = model([noisy_images, noise_rates**2])\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "        \n",
    "        next_diffusion_times = diffusion_times - step_size\n",
    "        next_noise_rates, next_signal_rates = diffusion_schedule(next_diffusion_times)\n",
    "        next_noisy_images = (next_signal_rates * pred_images + next_noise_rates * pred_noises)\n",
    "        \n",
    "    return pred_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6231f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = create_unet([32, 64, 32], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7a5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(encoded_images, unet, 100, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd166c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206ef29a148>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_latents = reverse_diffusion(unet, 8, 20)\n",
    "plt.imshow(generated_latents[2].numpy().reshape(4, 4 * 8), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "37ad05ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206f954db08>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_latents = reverse_diffusion(unet, 2, 20)\n",
    "generated_images = vae.decode(generated_latents)\n",
    "plt.imshow(generated_images[0].numpy().reshape(28, 28), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
