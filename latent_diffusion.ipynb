{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fa1c9b",
   "metadata": {},
   "source": [
    "# Latent Diffusion\n",
    "\n",
    "WIP implementation of latent diffusion from the paper [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752).\n",
    "\n",
    "Resources Used:\n",
    "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "- [Variational AutoEncoder](https://keras.io/examples/generative/vae/)\n",
    "- [Denoising Diffusion Implicit Models](https://keras.io/examples/generative/ddim/)\n",
    "\n",
    "ToDo:\n",
    "- Find colored dataset to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9252187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338ad422",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size  = 28\n",
    "autoencoder_depth = 10\n",
    "dropout = 0.1\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcb6ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], image_size, image_size, channels))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], image_size, image_size, channels))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79204bc6",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46257d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncoderBlock():\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        return encoded\n",
    "    \n",
    "    return apply\n",
    "\n",
    "def DecoderBlock():\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        return decoded\n",
    "    \n",
    "    return apply\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(4, 4, 8))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b05041b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = self.create_encoder()\n",
    "        self.decoder = self.create_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def create_encoder(self):\n",
    "        input_image = layers.Input(shape=(image_size, image_size, channels))\n",
    "        x = EncoderBlock()(input_image)\n",
    "        z_mean = layers.Conv2D(8, (2, 2), padding='same')(x)\n",
    "        z_log_var = layers.Conv2D(8, (2, 2), padding='same')(x)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "        return keras.Model(input_image, [z_mean, z_log_var, z])\n",
    "    \n",
    "    def create_decoder(self):\n",
    "        input_latent = layers.Input(shape=(4, 4, 8))\n",
    "        decoded = DecoderBlock()(input_latent)\n",
    "        return keras.Model(input_latent, decoded)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def encode(self, data):\n",
    "        _, _, z = self.encoder(data)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, data):\n",
    "        x = self.decoder(data)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ea75e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "vae.compile(optimizer='adam')\n",
    "vae.fit(x_train, epochs=200, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e35f0f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([59904, 4, 4, 8])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_images = vae.encode(x_train[0 : batch_size])\n",
    "batch_size = 512\n",
    "\n",
    "for i in range(1, int(x_train.shape[0] / batch_size)):\n",
    "    encoded = vae.encode(x_train[i*batch_size : i * batch_size + batch_size])\n",
    "    encoded_images = tf.concat([encoded_images, encoded], axis=0)\n",
    "\n",
    "encoded_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12c0f829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206f6475cc8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(encoded_images[0].numpy().reshape(4, 4 * 8), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "371f4b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([59904, 28, 28, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_images = vae.decode(encoded_images[0 : batch_size])\n",
    "batch_size = 512\n",
    "\n",
    "for i in range(1, int(x_train.shape[0] / batch_size)):\n",
    "    decoded = vae.decode(encoded_images[i*batch_size : i * batch_size + batch_size])\n",
    "    decoded_images = tf.concat([decoded_images, decoded], axis=0)\n",
    "\n",
    "decoded_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a5959432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206ef70cec8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(decoded_images[1].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83990d5",
   "metadata": {},
   "source": [
    "## Denoising U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "256b8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling.\n",
    "min_signal_rate = 0.02\n",
    "max_signal_rate = 0.95\n",
    "\n",
    "# Architecture.\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "widths = [32, 64, 96, 128]\n",
    "block_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1adee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_schedule(diffusion_times):\n",
    "    start_angle = tf.acos(max_signal_rate)\n",
    "    end_angle = tf.acos(min_signal_rate)\n",
    "\n",
    "    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "\n",
    "    signal_rates = tf.cos(diffusion_angles)\n",
    "    noise_rates = tf.sin(diffusion_angles)\n",
    "\n",
    "    return noise_rates, signal_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10013591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):\n",
    "    embedding_min_frequency = 1.0\n",
    "    frequencies = tf.exp(tf.linspace(tf.math.log(embedding_min_frequency),\n",
    "                         tf.math.log(embedding_max_frequency),\n",
    "                         embedding_dims // 2))\n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat([tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b720f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(width):\n",
    "    def apply(x):\n",
    "        input_width = x.shape[3]\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(width, (1, 1))(x)\n",
    "            \n",
    "        x = layers.Conv2D(width, (3, 3), padding='same', activation=keras.activations.swish)(x)\n",
    "        x = layers.LayerNormalization()(x + residual)\n",
    "        return x\n",
    "    \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb554cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x)\n",
    "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "        return x\n",
    "        \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ada302ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation='bilinear')(x)\n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x)\n",
    "        return x\n",
    "    \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3472ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unet(widths, block_depth):\n",
    "    noisy_images = keras.Input(shape=(4, 4, 8))\n",
    "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
    "\n",
    "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
    "    e = layers.UpSampling2D(size=4, interpolation=\"nearest\")(e)\n",
    "\n",
    "    x = layers.Conv2D(widths[0], kernel_size=1)(noisy_images)\n",
    "    x = layers.Concatenate()([x, e])\n",
    "\n",
    "    for width in widths[:-1]:\n",
    "        x = DownBlock(width, block_depth)(x)\n",
    "\n",
    "    for _ in range(block_depth):\n",
    "        x = ResidualBlock(widths[-1])(x)\n",
    "\n",
    "    for width in reversed(widths[:-1]):\n",
    "        x = UpBlock(width, block_depth)(x)\n",
    "\n",
    "    x = layers.Conv2D(8, kernel_size=1, kernel_initializer=\"zeros\")(x)\n",
    "    \n",
    "    unet = keras.Model([noisy_images, noise_variances], x, name=\"residual_unet\")\n",
    "    unet.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f28b04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, model, epochs, batch_size):\n",
    "    steps_per_epoch = int(train_data.shape[0] / batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(steps_per_epoch):\n",
    "            images = train_data[step * batch_size : step * batch_size + batch_size]\n",
    "            noises = tf.random.normal(shape=(batch_size, 4, 4, 8))\n",
    "            \n",
    "            diffusion_times = tf.random.uniform(shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0)\n",
    "            noise_rates, signal_rates = diffusion_schedule(diffusion_times)\n",
    "\n",
    "            noisy_images = signal_rates * images + noise_rates * noises\n",
    "            model.train_on_batch([noisy_images, noise_rates**2], noises)\n",
    "        \n",
    "        print('Epoch ' + str(epoch) + ' completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17defb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_diffusion(model, num_images, diffusion_steps):\n",
    "    initial_noise = tf.random.normal(shape=(num_images, 4, 4, 8))\n",
    "    step_size = 1.0 / diffusion_steps\n",
    "    \n",
    "    next_noisy_images = initial_noise\n",
    "    for step in range(diffusion_steps):\n",
    "        noisy_images = next_noisy_images\n",
    "        \n",
    "        diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
    "        noise_rates, signal_rates = diffusion_schedule(diffusion_times)\n",
    "        \n",
    "        pred_noises = model([noisy_images, noise_rates**2])\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "        \n",
    "        next_diffusion_times = diffusion_times - step_size\n",
    "        next_noise_rates, next_signal_rates = diffusion_schedule(next_diffusion_times)\n",
    "        next_noisy_images = (next_signal_rates * pred_images + next_noise_rates * pred_noises)\n",
    "        \n",
    "    return pred_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6231f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = create_unet([32, 64, 32], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7a5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(encoded_images, unet, 10000, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cd166c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206f7bc5f88>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAABJCAYAAAAUl2zPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJbElEQVR4nO3de4xV1RXH8e/PQQQHAowgoFIVJBLSVKiE2JQQoylCE7VNKtFYIvEPmlgTDf2jTfmjtkkT07TY/lEhtJpIYktJpa0JJC3GR8EoFaiWlwXrewQpjsrgA3ms/nEPzVRnmHVhzsw59PdJJtw5d7H23rPnrnvmPO5WRGBmZtV11kB3wMzMTs6F2sys4lyozcwqzoXazKziXKjNzCrOhdrMrOIGlZF0xIgRMW7cuF7jOjs70znffffdVNzo0aPTOVtbW1Nxhw4dSuccNWpUKu79999P5/zwww9TcUOGDEnnzI5p2LBh6ZxHjhxJxZ11Vn7/oKWlJRV37rnnpuKOHTuWbvvo0aN9njM79mzbAIMG5V7G7e3t6Zxjx45NxWVfQwCHDx9OxTXzesv+zjfz8xwxYkQqrpl+Zn5O+/fv5+DBg+ruudQMS5oL/AJoAX4dEfeeLH7cuHGsWLGi17yPP/54pnkAVq9enYpbtGhROueMGTNScU8//XQ65/z581Nxa9euTefcsmVLKm7KlCnpnNkxzZ49O51z7969qbhm3lCGDx+eips+fXoqrpmdg46Ojj6Ng/wbyjvvvJPOOWbMmFTckiVL0jmzr6Mrr7wynfOVV15JxW3cuDGdc+rUqam4Zn6ec+bMScU988wz6ZxXXXVVrzGLFy/u8ble394ltQC/BOYBU4FbJOV+OmZmdtoyf4fNBF6KiJcj4hNgFXBjud0yM7MTMoX6QuCNLt+/WWwzM7N+0GdXfUhaJGmzpM3NnCgzM7OTyxTqdmBCl+8vKrb9j4hYEREzImJG9qypmZn1LlOonwMmS7pU0mDgZuDRcrtlZmYn9Hp5XkQclXQn8Gcal+c9GBE7Su+ZmZkByeuoI2IdsK7kvpiZWTdKuTPxyJEjqZsfbrrppnTOjz76KBU3fvz4dM6nnnoqFXfgwIF0zltvvTUVd/vtt6dzTpw4MRV3/PjxdM4rrrgiFTd06NB0zmw/X3zxxXTO+++/PxU3a9asVNwNN9yQbvvJJ59MxTVzh9q1116bisuOB2DlypWpuHXr8vtay5cvT8U18/uRvct027Zt6ZyXXXZZKi57QxTAfffdl4qbO3duOuezzz7ba8wHH3zQ43P+rA8zs4pzoTYzqzgXajOzinOhNjOrOBdqM7OKc6E2M6s4F2ozs4pzoTYzqzgXajOzinOhNjOrOEVEnydta2uLzLpjCxcuTOfct29fKu6tt95K58ze/jpp0qR0zu3bt6firr/++nTOpUuXpuLuuOOOdM7sIryrVq1K53zttddScW1tbemc2TnKrte4c+fOdNvZtfumTZuWzpldi3DHjvznnl188cWpuGZ+j/fs2ZOKy64BCflb7V9//fV0zuzHFmzYsCGdM7ug88cff5zOmVmA+LHHHqOjo6PbxW0zayZOkPSEpJ2Sdki6K907MzM7bZkPZToKfCcitkoaDmyRtD4i8rsmZmZ2ynrdo46IvRGxtXjcCezCayaamfWbpk4mSroEmA5sKqU3Zmb2GelCLWkY8Ahwd0Qc7Ob5/y5ue/jw4b7so5nZ/7VUoZZ0No0i/XBErOkupuvituecc05f9tHM7P9a5qoPAQ8AuyIid52YmZn1mcwe9ZeBBcA1kp4vvr5acr/MzKyQWYV8I9DtRdhmZla+Uha3bW1tZebMmb3GNXPX25AhQ1JxI0eOTOdcs6bbw+2fsWDBgnTOtWvXpuIyi12ekF3odP369emc5513Xiouc0fVCceOHUvFdXZ2pnNefvnlqbjs3YEXXHBBuu3rrrsuFTd58uR0zt27d6fisncwAixZsiQVN2HChHTO9vb2VNz555+fzpld3LaZfg4ePDgVl73TEmDevHmpuOwdwwDLli3rNWbTpp4vpvNnfZiZVZwLtZlZxblQm5lVnAu1mVnFuVCbmVWcC7WZWcW5UJuZVZwLtZlZxblQm5lVnAu1mVnFlbK4raR/A59e6XQ0cKDPGxs4Hk/1nWlj8niq73TGdHFEjOnuiVIKdbcNSZsjYka/NNYPPJ7qO9PG5PFUX1lj8qEPM7OKc6E2M6u4/izUK/qxrf7g8VTfmTYmj6f6ShlTvx2jNjOzU+NDH2ZmFVd6oZY0V9I/Jb0k6Xtlt9cfJL0qaVuxfuTmge5PsyQ9KGm/pO1dtrVJWi9pT/HvqIHsYzN6GM89ktrruM6npAmSnpC0U9IOSXcV2+s8Rz2NqZbzJGmIpL9JeqEYzw+L7ZdK2lTUu99Jyi1B01t7ZR76kNQC7Aa+ArwJPAfcEhE7S2u0H0h6FZgREbW8BlTSbOAQsDIiPl9s+wnQERH3Fm+ooyLiuwPZz6wexnMPcCgifjqQfTsVksYD4yNiq6ThwBbga8BC6jtHPY1pPjWcJ0kCWiPikKSzgY3AXcBiYE1ErJK0HHghInpfh6sXZe9RzwReioiXI+ITYBVwY8ltWi8i4q9Ax6c23wg8VDx+iMaLqBZ6GE9tRcTeiNhaPO4EdgEXUu856mlMtRQNh4pvzy6+ArgG+H2xvc/mqOxCfSHwRpfv36TGk9NFAH+RtEVSfhXSahsbEXuLx/uAsQPZmT5yp6R/FIdGanOYoCtJlwDTgU2cIXP0qTFBTedJUouk54H9wHrgX8B7EXG0COmzeueTiadmVkR8EZgHfLv40/uMEY3jYXW/HGgZMAmYBuwFfjagvTkFkoYBjwB3R8TBrs/VdY66GVNt5ykijkXENOAiGkcPppTVVtmFuh3ouvb7RcW2WouI9uLf/cAfaExS3b1dHEc8cTxx/wD357RExNvFC+k48CtqNkfFcc9HgIcjYk2xudZz1N2Y6j5PABHxHvAE8CVgpKRBxVN9Vu/KLtTPAZOLM6GDgZuBR0tus1SSWouTIUhqBeYA20/+v2rhUeC24vFtwJ8GsC+n7URBK3ydGs1RcaLqAWBXRCzt8lRt56inMdV1niSNkTSyeDyUxgUTu2gU7G8UYX02R6Xf8FJcbvNzoAV4MCJ+XGqDJZM0kcZeNMAg4Dd1G5Ok3wJX0/ikr7eBHwB/BFYDn6PxyYfzI6IWJ+h6GM/VNP6cDuBV4Ftdju9WmqRZwAZgG3C82Px9Gsd06zpHPY3pFmo4T5K+QONkYQuNHd7VEfGjoj6sAtqAvwPfjIjDp92e70w0M6s2n0w0M6s4F2ozs4pzoTYzqzgXajOzinOhNjOrOBdqM7OKc6E2M6s4F2ozs4r7DwcgKAzeMcXgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_latents = reverse_diffusion(unet, 8, 20)\n",
    "plt.imshow(generated_latents[2].numpy().reshape(4, 4 * 8), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "37ad05ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206f9ac03c8>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKnklEQVR4nO3dX4il9X3H8fenmtxshK6VDsvG1LR4lwtTxCsp9iLBerPmRuLVhhQmF7Wkd5HkIkIIhNCml4UNkWxCagiodZHSxEqIuQqOYnVVEm1YyS7rLLIJMd6k0W8v5lmZrHPmzJ5/z3G/7xcMc+aZM+d8Oex7z/M8Z+b8UlVIuvr9ydgDSFoNY5eaMHapCWOXmjB2qYlrV3lnSTz1Ly1ZVWWv7XM9sye5M8nPk7ya5P55bkvScmXW19mTXAP8AvgEcBZ4Gri3ql7a52d8ZpeWbBnP7LcBr1bVL6vq98D3gWNz3J6kJZon9qPAr3Z9fXbY9keSbCbZSrI1x31JmtPST9BV1QngBLgbL41pnmf2c8CNu77+8LBN0hqaJ/angZuTfDTJB4FPA6cWM5akRZt5N76q/pDkPuCHwDXAg1X14sImk7RQM7/0NtOdecwuLd1SfqlG0vuHsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS03MvD47QJIzwJvA28AfqurWRQwlafHmin3wt1X1xgJuR9ISuRsvNTFv7AX8KMkzSTb3ukKSzSRbSbbmvC9Jc0hVzf7DydGqOpfkz4EngH+sqqf2uf7sdybpQKoqe22f65m9qs4Nny8AjwK3zXN7kpZn5tiTHEpy3aXLwCeB04saTNJizXM2fgN4NMml2/n3qvqvhUwlAYcOHdr3+2+99daKJrk6zHXMfsV35jG7roCxz2Ypx+yS3j+MXWrC2KUmjF1qwtilJjwbL11lPBsvNWfsUhPGLjVh7FITxi41YexSE8YuNbGIN5yUrjrTfv9k+NPu9xWf2aUmjF1qwtilJoxdasLYpSaMXWrC2KUmfJ1dLa3yfRzWhc/sUhPGLjVh7FITxi41YexSE8YuNWHsUhO+zq6rVsfX0vcz9Zk9yYNJLiQ5vWvb9UmeSPLK8PnwcseUNK+D7MZ/G7jzsm33A09W1c3Ak8PXktbY1Nir6ing4mWbjwEnh8sngbsXO5akRZv1mH2jqs4Pl18HNiZdMckmsDnj/UhakLlP0FVV7bdgY1WdAE6ACztKY5r1pbftJEcAhs8XFjeSpGWYNfZTwPHh8nHgscWMI2lZpq7PnuQh4A7gBmAb+DLwH8APgI8ArwH3VNXlJ/H2ui1347UwY76Ovs7vGz9pffapsS+SsWuRjH1vk2L312WlJoxdasLYpSaMXWrC2KUm/BNXrS3Pti+Wz+xSE8YuNWHsUhPGLjVh7FITxi41YexSE77OrrU17bXu7e3tfb+/sTHx3dJa8pldasLYpSaMXWrC2KUmjF1qwtilJoxdasJ3l5WuMr67rNScsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNTI09yYNJLiQ5vWvbA0nOJXlu+LhruWNKmtdBntm/Ddy5x/Z/rapbho//XOxYkhZtauxV9RRwcQWzSFqieY7Z70vy/LCbf3jSlZJsJtlKsjXHfUma04H+ECbJTcDjVfWx4esN4A2ggK8AR6rqswe4Hf8QRlqyhf4hTFVtV9XbVfUO8E3gtnmGk7R8M8We5MiuLz8FnJ50XUnrYer7xid5CLgDuCHJWeDLwB1JbmFnN/4M8LnljShpEXzzCukq45tXSM0Zu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71MTU2JPcmOTHSV5K8mKSzw/br0/yRJJXhs+Hlz+upFlNXZ89yRHgSFU9m+Q64BngbuAzwMWq+lqS+4HDVfWFKbfl+uzSks28PntVna+qZ4fLbwIvA0eBY8DJ4Won2fkPQNKauvZKrpzkJuDjwM+Ajao6P3zrdWBjws9sAptzzChpAabuxr97xeRDwE+Ar1bVI0l+U1V/uuv7v66qfY/b3Y2Xlm/m3XiAJB8AHga+V1WPDJu3h+P5S8f1FxYxqKTlOMjZ+ADfAl6uqm/s+tYp4Phw+Tjw2OLHk7QoBzkbfzvwU+AF4J1h8xfZOW7/AfAR4DXgnqq6OOW23I2XlmzSbvyBj9kXwdil5ZvrmF3S+5+xS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUxEHWZ78xyY+TvJTkxSSfH7Y/kORckueGj7uWP66kWR1kffYjwJGqejbJdcAzwN3APcDvquqfD3xnLtksLd2kJZuvPcAPngfOD5ffTPIycHSx40latis6Zk9yE/Bx4GfDpvuSPJ/kwSSHJ/zMZpKtJFvzjSppHlN349+9YvIh4CfAV6vqkSQbwBtAAV9hZ1f/s1Nuw914ackm7cYfKPYkHwAeB35YVd/Y4/s3AY9X1cem3I6xS0s2KfaDnI0P8C3g5d2hDyfuLvkUcHreISUtz0HOxt8O/BR4AXhn2PxF4F7gFnZ2488AnxtO5u13Wz6zS0s21278ohi7tHwz78ZLujoYu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9TE1DecXLA3gNd2fX3DsG0drets6zoXONusFjnbX0z6xkr/nv09d55sVdWtow2wj3WdbV3nAmeb1apmczdeasLYpSbGjv3EyPe/n3WdbV3nAmeb1UpmG/WYXdLqjP3MLmlFjF1qYpTYk9yZ5OdJXk1y/xgzTJLkTJIXhmWoR12fblhD70KS07u2XZ/kiSSvDJ/3XGNvpNnWYhnvfZYZH/WxG3v585Ufsye5BvgF8AngLPA0cG9VvbTSQSZIcga4tapG/wWMJH8D/A74zqWltZJ8HbhYVV8b/qM8XFVfWJPZHuAKl/Fe0myTlhn/DCM+dotc/nwWYzyz3wa8WlW/rKrfA98Hjo0wx9qrqqeAi5dtPgacHC6fZOcfy8pNmG0tVNX5qnp2uPwmcGmZ8VEfu33mWokxYj8K/GrX12dZr/XeC/hRkmeSbI49zB42di2z9TqwMeYwe5i6jPcqXbbM+No8drMsfz4vT9C91+1V9dfA3wH/MOyurqXaOQZbp9dO/w34K3bWADwP/MuYwwzLjD8M/FNV/Xb398Z87PaYayWP2xixnwNu3PX1h4dta6Gqzg2fLwCPsnPYsU62L62gO3y+MPI876qq7ap6u6reAb7JiI/dsMz4w8D3quqRYfPoj91ec63qcRsj9qeBm5N8NMkHgU8Dp0aY4z2SHBpOnJDkEPBJ1m8p6lPA8eHyceCxEWf5I+uyjPekZcYZ+bEbffnzqlr5B3AXO2fk/xf40hgzTJjrL4H/GT5eHHs24CF2duv+j51zG38P/BnwJPAK8N/A9Ws023fZWdr7eXbCOjLSbLezs4v+PPDc8HHX2I/dPnOt5HHz12WlJjxBJzVh7FITxi41YexSE8YuNWHsUhPGLjXx/9uqmbtNPyhCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_latents = reverse_diffusion(unet, 2, 20)\n",
    "generated_images = vae.decode(generated_latents)\n",
    "plt.imshow(generated_images[0].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e5dfb226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../latent_diffusion_unet\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../latent_diffusion_unet\\assets\n"
     ]
    }
   ],
   "source": [
    "unet.save('../latent_diffusion_unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f06630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
